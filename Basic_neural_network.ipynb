{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYI/zMC1Nu7l6ZH5h5qr6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrieVarshini2004/Deep-Learning/blob/main/Basic_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgCs5YbYpgkW",
        "outputId": "c0377042-f4e2-4c23-badf-af0bd100923d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "NEURAL NETWORK IMPLEMENTATION\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "INITIALIZING NETWORK ARCHITECTURE\n",
            "Input layer: 5 nodes\n",
            "Hidden layer 1: 2 nodes\n",
            "Hidden layer 2: 3 nodes\n",
            "Hidden layer 3: 2 nodes\n",
            "Output layer: 3 nodes\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FORWARD PROPAGATION\n",
            "==================================================\n",
            "\n",
            "Input values: [0.41, 0.45, 0.4 , 1.  , 0.18]\n",
            "\n",
            "==================== LAYER_1 ======================\n",
            "node_1:\n",
            "  Weights: [0.15, 0.74, 0.26, 0.53, 0.01]\n",
            "  Bias: 0.9200\n",
            "  Weighted Sum: 1.9503\n",
            "  Activated Output: 0.8755\n",
            "\n",
            "node_2:\n",
            "  Weights: [0.9 , 0.03, 0.96, 0.14, 0.28]\n",
            "  Bias: 0.6100\n",
            "  Weighted Sum: 1.5669\n",
            "  Activated Output: 0.8273\n",
            "\n",
            "Layer outputs: [array([0.8755]), array([0.8273])]\n",
            "\n",
            "==================== LAYER_2 ======================\n",
            "node_1:\n",
            "  Weights: [0.94, 0.85]\n",
            "  Bias: 0.0000\n",
            "  Weighted Sum: 3.0480\n",
            "  Activated Output: 0.9547\n",
            "\n",
            "node_2:\n",
            "  Weights: [0.52, 0.55]\n",
            "  Bias: 0.4900\n",
            "  Weighted Sum: 2.3120\n",
            "  Activated Output: 0.9099\n",
            "\n",
            "node_3:\n",
            "  Weights: [0.77, 0.16]\n",
            "  Bias: 0.7600\n",
            "  Weighted Sum: 2.3436\n",
            "  Activated Output: 0.9124\n",
            "\n",
            "Layer outputs: [array([0.9547]), array([0.9099]), array([0.9124])]\n",
            "\n",
            "==================== LAYER_3 ======================\n",
            "node_1:\n",
            "  Weights: [0.02, 0.14, 0.12]\n",
            "  Bias: 0.3100\n",
            "  Weighted Sum: 1.0876\n",
            "  Activated Output: 0.7479\n",
            "\n",
            "node_2:\n",
            "  Weights: [0.67, 0.47, 0.82]\n",
            "  Bias: 0.2900\n",
            "  Weighted Sum: 5.7329\n",
            "  Activated Output: 0.9968\n",
            "\n",
            "Layer outputs: [array([0.7479]), array([0.9968])]\n",
            "\n",
            "==================== OUTPUT =======================\n",
            "node_1:\n",
            "  Weights: [0.73, 0.7 ]\n",
            "  Bias: 0.3300\n",
            "  Weighted Sum: 2.8249\n",
            "  Activated Output: 0.9440\n",
            "\n",
            "node_2:\n",
            "  Weights: [0.33, 0.98]\n",
            "  Bias: 0.6200\n",
            "  Weighted Sum: 2.9056\n",
            "  Activated Output: 0.9481\n",
            "\n",
            "node_3:\n",
            "  Weights: [0.95, 0.77]\n",
            "  Bias: 0.8300\n",
            "  Weighted Sum: 3.8309\n",
            "  Activated Output: 0.9788\n",
            "\n",
            "==================================================\n",
            "\n",
            "FINAL PREDICTIONS: [array([0.944]), array([0.9481]), array([0.9788])]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-916811055de3>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"  Bias: {float(node_data['bias']):.4f}\")\n",
            "<ipython-input-3-916811055de3>:62: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"  Weighted Sum: {float(weighted_sum):.4f}\")\n",
            "<ipython-input-3-916811055de3>:63: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"  Activated Output: {float(node_output):.4f}\\n\")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
        "    num_nodes_previous = num_inputs\n",
        "    network = {}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"INITIALIZING NETWORK ARCHITECTURE\")\n",
        "    print(f\"Input layer: {num_inputs} nodes\")\n",
        "\n",
        "    for layer in range(num_hidden_layers + 1):\n",
        "        if layer == num_hidden_layers:\n",
        "            layer_name = 'output'\n",
        "            num_nodes = num_nodes_output\n",
        "            print(f\"Output layer: {num_nodes} nodes\")\n",
        "        else:\n",
        "            layer_name = f'layer_{layer+1}'\n",
        "            num_nodes = num_nodes_hidden[layer]\n",
        "            print(f\"Hidden layer {layer+1}: {num_nodes} nodes\")\n",
        "\n",
        "        network[layer_name] = {}\n",
        "        for node in range(num_nodes):\n",
        "            node_name = f'node_{node+1}'\n",
        "            weights = np.around(np.random.uniform(size=num_nodes_previous), decimals=2)\n",
        "            bias = np.around(np.random.uniform(size=1), decimals=2)\n",
        "            network[layer_name][node_name] = {\n",
        "                'weights': weights,\n",
        "                'bias': bias,\n",
        "            }\n",
        "\n",
        "        num_nodes_previous = num_nodes\n",
        "\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "    return network\n",
        "\n",
        "def compute_weighted_sum(inputs, weights, bias):\n",
        "    return np.sum(inputs * weights) + bias\n",
        "\n",
        "def node_activation(weighted_sum):\n",
        "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))\n",
        "\n",
        "def forward_propagate(network, inputs):\n",
        "    print(\"=\"*50)\n",
        "    print(\"FORWARD PROPAGATION\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nInput values: {np.array2string(inputs, precision=4, separator=', ')}\\n\")\n",
        "\n",
        "    layer_inputs = list(inputs)\n",
        "\n",
        "    for layer_name, layer_data in network.items():\n",
        "        print(f\"{'='*20} {layer_name.upper()} {'='*(29-len(layer_name))}\")\n",
        "        layer_outputs = []\n",
        "\n",
        "        for node_name, node_data in layer_data.items():\n",
        "            weighted_sum = compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias'])\n",
        "            node_output = node_activation(weighted_sum)\n",
        "            layer_outputs.append(np.around(node_output, decimals=4))\n",
        "\n",
        "            print(f\"{node_name}:\")\n",
        "            print(f\"  Weights: {np.array2string(node_data['weights'], precision=4, separator=', ')}\")\n",
        "            print(f\"  Bias: {float(node_data['bias']):.4f}\")\n",
        "            print(f\"  Weighted Sum: {float(weighted_sum):.4f}\")\n",
        "            print(f\"  Activated Output: {float(node_output):.4f}\\n\")\n",
        "\n",
        "        if layer_name != 'output':\n",
        "            print(f\"Layer outputs: {layer_outputs}\\n\")\n",
        "\n",
        "        layer_inputs = layer_outputs\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFINAL PREDICTIONS: {layer_inputs}\")\n",
        "    print(\"=\"*50)\n",
        "    return layer_inputs\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(12)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"NEURAL NETWORK IMPLEMENTATION\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "my_network = initialize_network(5, 3, [2, 3, 2], 3)\n",
        "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
        "\n",
        "predictions = forward_propagate(my_network, inputs)"
      ]
    }
  ]
}